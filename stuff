
def geGLOBAL_KEY_POOL = []  # Store all keys
GLOBAL_KEY_USED = set()  # Track used keys

def extend_global_key_pool(key, new_size):
    """
    Extend the global key pool with new keys using a given JAX random key.
    """
    global GLOBAL_KEY_POOL
    # Generate additional keys
    new_keys = jax.random.split(key, num=new_size)
    GLOBAL_KEY_POOL.extend(new_keys)

def generate_dataset_method2(gate, n_qubits, training_size, key, global_size=100):
    """
    Generate the dataset of input and output states according to the gate provided,
    while ensuring globally unique states across calls.
    """
    global GLOBAL_KEY_POOL, GLOBAL_KEY_USED

    # Extend the global key pool if necessary
    if len(GLOBAL_KEY_POOL) < len(GLOBAL_KEY_USED) + training_size:
        additional_keys_needed = len(GLOBAL_KEY_USED) + training_size - len(GLOBAL_KEY_POOL)
        extend_global_key_pool(key, additional_keys_needed)

    # Generate random state vectors from the global pool
    X = []
    unused_keys = (k for k in GLOBAL_KEY_POOL if k not in GLOBAL_KEY_USED)
    for i, subkey in zip(range(training_size), unused_keys):
        GLOBAL_KEY_USED.add(subkey)  # Mark the key as used
        subkey = jax.random.fold_in(subkey, i)  # Fold in the index to guarantee uniqueness
        seed_value = int(jax.random.randint(subkey, (1,), 0, 2**32 - 1)[0])  # Get a scalar seed

        # Use the seed to generate the random state vector
        state_vec = random_statevector(2**n_qubits, seed=seed_value).data
        X.append(np.asarray(state_vec, dtype=jnp.complex128))

    X = np.stack(X)
    return X, None


averaged_data = all_data_df.groupby(['Trotter_Step', 'Reservoir Count', 'N_C']).agg(
    Average_Fidelity=('Avg_Fidelity', 'mean'),
    Std_Dev=('Avg_Fidelity', 'std'),
    Count=('Avg_Fidelity', 'count'),  # For calculating standard error
    Test_Results=('Test Results', lambda x: [np.array(lst) for lst in x])  # Keep Test Results as list of arrays
).reset_index()

# Add a new column for Standard Error
averaged_data['Standard_Error'] = averaged_data['Std_Dev'] / averaged_data['Count'].pow(0.5)

# Optional: Drop 'Count' if you no longer need it
averaged_data = averaged_data.drop(columns=['Count'])

# Preview the result
print(averaged_data.head())
reservoir_count = 1

trot = 1
N_ctrl = 1
# Filter the row based on your conditions
tes = averaged_data[
    (averaged_data['N_C'] == N_ctrl) & 
    (averaged_data['Reservoir Count'] == reservoir_count) & 
    (averaged_data['Trotter_Step'] == trot)
]

# Access the values of Average_Fidelity and Std_Dev as floats
average_fidelity = float(tes['Average_Fidelity'].values[0])
std_dev = float(tes['Std_Dev'].values[0])
# Access the Test_Results as a list of arrays
test_results = tes['Test_Results'].values[0]  # This will be a list of arrays

# Print the results
print("Average Fidelity:", average_fidelity)
print("Standard Deviation:", std_dev)
print("Test Results (List of Arrays):", np.mean(test_results))
# averaged_data.head()
