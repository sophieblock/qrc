warmstart = 750
factor = 0.1
patience = 10
rtol_values = [1e-4, 1e-5]
atol = 0.0
cooldown = 2
accumulation_size = 3
min_scale = 0.0

triggered_epochs = {rtol: [] for rtol in rtol_values}

state = {
    rtol: {
        'best_value': costs_analog[warmstart - 1],
        'plateau_count': 0,
        'cooldown_count': 0,
        'scale': 1.0,
        'accumulated_count': 0,
        'accumulated_value': 0.0
    } for rtol in rtol_values
}

for epoch in range(warmstart, len(costs_analog)):
    current_cost = costs_analog[epoch]

    for rtol in rtol_values:
        s = state[rtol]

        # Accumulate the current cost
        s['accumulated_count'] += 1
        s['accumulated_value'] += current_cost

        if s['accumulated_count'] == accumulation_size:
            avg_accumulated_value = s['accumulated_value'] / accumulation_size
            threshold = (1 - rtol) * s['best_value'] - atol

            # Check for improvement
            if avg_accumulated_value < threshold:
                s['best_value'] = avg_accumulated_value
                s['plateau_count'] = 0
            else:
                s['plateau_count'] += 1

            # Cooldown logic
            if s['cooldown_count'] > 0:
                s['cooldown_count'] -= 1
            elif s['plateau_count'] >= patience:
                s['scale'] *= factor
                s['cooldown_count'] = cooldown
                triggered_epochs[rtol].append(epoch)
                s['plateau_count'] = 0

            # Reset accumulation
            s['accumulated_count'] = 0
            s['accumulated_value'] = 0.0

# Output results
for rtol in rtol_values:
    print(f"Epochs triggering reduction with rtol={rtol}: {triggered_epochs[rtol]}")
# Output the results
print("Epochs that would trigger a reduction with rtol = 1e-4:", triggered_epochs_1e4)
# print("Epochs that would trigger a reduction with rtol = 1e-5:", triggered_epochs_1e5)
